{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 182633,
          "sourceType": "datasetVersion",
          "datasetId": 78313
        }
      ],
      "dockerImageVersionId": 30674,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "model_cnn",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FarmIA/farmia/blob/main/model_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'new-plant-diseases-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F78313%2F182633%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240326%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240326T213432Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D0e7d7ac286d0d481431c3a4124ff4ba41c0533a5ae63c6e59828a3110ce0fa4980b7e61d9597aee8110937692012e478f24d0c43d0c19e120a0e358c5c3ab4e22656073c2aaf590a0cb94c1cd5ac49faa51e7968ef4b317b21492ce226080740338018af32ca1e5be339bf664ed279c64d1b59e67d41dbb4188f13bd8a427273e3722929a0199fd0670d78f3704c1802c053d7aaa2b5bb2076a198b3d184837c2f802fee912525c2293fd8bc7bc7d3354cb840eae8c35621c928832ec356537264bc52a525e26a9a65d2870556f1461bd5fee1f2d1008e3f3b2e9785f75d353b5b8cecd5fd0e3ba5513768e1a8bd3f7ad0dabed04d3cb834de06cb9989116185'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "iis7au8-r53r"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "train_dir = \"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\"\n",
        "valid_dir = \"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\"\n",
        "\n",
        "# Définition des paramètres\n",
        "batch_size = 32\n",
        "img_height = 256\n",
        "img_width = 256\n",
        "\n",
        "# Chargement des images depuis le dossier\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  valid_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "\n",
        "# Affichage des classes\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-03-24T08:11:43.760604Z",
          "iopub.execute_input": "2024-03-24T08:11:43.761417Z",
          "iopub.status.idle": "2024-03-24T08:12:38.371413Z",
          "shell.execute_reply.started": "2024-03-24T08:11:43.761383Z",
          "shell.execute_reply": "2024-03-24T08:12:38.370355Z"
        },
        "trusted": true,
        "id": "2WEqtUEpr534"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Obtenir le premier lot de données\n",
        "images, labels = next(iter(train_ds))\n",
        "\n",
        "# Imprimer les dimensions du premier lot de données\n",
        "print(\"Dimensions des images:\", images.shape)\n",
        "print(\"Dimensions des étiquettes:\", labels.shape)\n",
        "\n",
        "# Afficher la première image du lot\n",
        "img = Image.fromarray(images[0].numpy().astype('uint8'))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Désactive les axes\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T08:12:53.172714Z",
          "iopub.execute_input": "2024-03-24T08:12:53.173431Z",
          "iopub.status.idle": "2024-03-24T08:12:54.244872Z",
          "shell.execute_reply.started": "2024-03-24T08:12:53.173398Z",
          "shell.execute_reply": "2024-03-24T08:12:54.243906Z"
        },
        "trusted": true,
        "id": "WZf10DMfr536"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.InputLayer(shape=(256, 256, 3)))\n",
        "\n",
        "model.add(keras.layers.Conv2D(32,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(keras.layers.Conv2D(32,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(keras.layers.MaxPooling2D(3,3))\n",
        "\n",
        "model.add(keras.layers.Conv2D(64,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(keras.layers.Conv2D(64,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(keras.layers.MaxPooling2D(3,3))\n",
        "\n",
        "model.add(keras.layers.Conv2D(128,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(keras.layers.Conv2D(128,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(keras.layers.MaxPooling2D(3,3))\n",
        "\n",
        "model.add(keras.layers.Conv2D(256,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "model.add(keras.layers.Conv2D(256,(3,3),activation=\"relu\",padding=\"same\"))\n",
        "\n",
        "model.add(keras.layers.Conv2D(512,(5,5),activation=\"relu\",padding=\"same\"))\n",
        "model.add(keras.layers.Conv2D(512,(5,5),activation=\"relu\",padding=\"same\"))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "model.add(keras.layers.Dense(1568,activation=\"relu\"))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(keras.layers.Dense(38,activation=\"softmax\"))\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=opt,loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T08:12:58.49115Z",
          "iopub.execute_input": "2024-03-24T08:12:58.492122Z",
          "iopub.status.idle": "2024-03-24T08:12:58.837328Z",
          "shell.execute_reply.started": "2024-03-24T08:12:58.492086Z",
          "shell.execute_reply": "2024-03-24T08:12:58.836458Z"
        },
        "trusted": true,
        "id": "BdzojQdqr538"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entraînement du modèle\n",
        "\n",
        "from tensorflow.keras import callbacks\n",
        "\n",
        "# Fonction de callback\n",
        "early_stopping = callbacks.EarlyStopping(\n",
        "    min_delta=0.001,\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "                    validation_data=val_ds,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                   callbacks=[early_stopping])\n",
        "\n",
        "# Visualisation de l'historique de l'entraînement\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T08:13:13.505814Z",
          "iopub.execute_input": "2024-03-24T08:13:13.506554Z",
          "iopub.status.idle": "2024-03-24T09:08:11.510134Z",
          "shell.execute_reply.started": "2024-03-24T08:13:13.506517Z",
          "shell.execute_reply": "2024-03-24T09:08:11.509138Z"
        },
        "trusted": true,
        "id": "1FrOHn5Pr53-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"mon_modele_entrene.keras\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T09:20:53.733714Z",
          "iopub.execute_input": "2024-03-24T09:20:53.73411Z",
          "iopub.status.idle": "2024-03-24T09:20:57.026714Z",
          "shell.execute_reply.started": "2024-03-24T09:20:53.734081Z",
          "shell.execute_reply": "2024-03-24T09:20:57.025735Z"
        },
        "trusted": true,
        "id": "ywgoj3XWr54A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Charger une nouvelle image\n",
        "image_path = \"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid/Blueberry___healthy/067e7729-ebb3-4824-80dc-9ceda52f47b8___RS_HL 5388.JPG\"\n",
        "img = Image.open(image_path)\n",
        "\n",
        "# Prétraiter l'image\n",
        "img_array = np.array(img)  # Convertir l'image en un tableau numpy\n",
        "img_array = img_array / 255.0  # Normaliser les valeurs des pixels entre 0 et 1\n",
        "img_array = np.expand_dims(img_array, axis=0)  # Ajouter une dimension supplémentaire pour correspondre à l'entrée attendue du modèle\n",
        "\n",
        "# Faire une prédiction avec le modèle\n",
        "predictions = model.predict(img_array)\n",
        "predicted_class_index = np.argmax(predictions)\n",
        "\n",
        "# Obtenir le nom de la classe prédite (à remplacer par vos classes spécifiques)\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "\n",
        "# Afficher l'image avec le titre de la classe prédite et la probabilité associée\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Classe prédite : {predicted_class_name}\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T00:21:26.709597Z",
          "iopub.execute_input": "2024-03-24T00:21:26.710014Z",
          "iopub.status.idle": "2024-03-24T00:21:29.613483Z",
          "shell.execute_reply.started": "2024-03-24T00:21:26.709984Z",
          "shell.execute_reply": "2024-03-24T00:21:29.612587Z"
        },
        "trusted": true,
        "id": "1T7z567er54B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "test_dir = \"/kaggle/input/new-plant-diseases-dataset/test/test\"\n",
        "\n",
        "for filename in os.listdir(test_dir):\n",
        "    img_path = os.path.join(test_dir, filename)\n",
        "\n",
        "    # Charger l'image et la prétraiter\n",
        "    img = Image.open(img_path)\n",
        "    img_array = np.array(img) / 255.0  # Normaliser les valeurs des pixels\n",
        "\n",
        "    # Ajouter une dimension supplémentaire pour correspondre à l'entrée attendue du modèle\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Faire une prédiction avec le modèle\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(predictions)\n",
        "    predicted_probability = predictions[0][predicted_class_index]\n",
        "\n",
        "    # Obtenir le nom de la classe prédite\n",
        "    predicted_class_name = class_names[predicted_class_index]\n",
        "\n",
        "    # Afficher l'image avec le titre de la classe prédite et la probabilité associée\n",
        "    print(f\"Image : {filename}\\nPrédiction : {predicted_class_name} (Probabilité : {predicted_probability:.2f})\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T00:21:56.04958Z",
          "iopub.execute_input": "2024-03-24T00:21:56.050399Z",
          "iopub.status.idle": "2024-03-24T00:21:58.253311Z",
          "shell.execute_reply.started": "2024-03-24T00:21:56.050364Z",
          "shell.execute_reply": "2024-03-24T00:21:58.252312Z"
        },
        "trusted": true,
        "id": "_UCBVLbkr54E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Charger le modèle externe\n",
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model(\"/kaggle/working/mon_modele_entrene.keras\")\n",
        "\n",
        "# Examiner les poids du modèle\n",
        "for layer in model.layers:\n",
        "    print(\"Layer Name:\", layer.name)\n",
        "    print(\"Weights:\")\n",
        "    for weight in layer.weights:\n",
        "        print(weight.shape)  # Afficher la forme des poids de la couche\n",
        "    print()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T09:21:11.979836Z",
          "iopub.execute_input": "2024-03-24T09:21:11.980531Z",
          "iopub.status.idle": "2024-03-24T09:21:21.477991Z",
          "shell.execute_reply.started": "2024-03-24T09:21:11.980478Z",
          "shell.execute_reply": "2024-03-24T09:21:21.477035Z"
        },
        "trusted": true,
        "id": "JjtwwgS_r54G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}